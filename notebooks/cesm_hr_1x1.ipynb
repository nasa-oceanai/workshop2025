{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de4d98fd-fc9f-49c4-acec-5722402520bd",
   "metadata": {},
   "source": [
    "# Data tutorial - CESM HR regridded \n",
    "\n",
    "* Notebook creator: Jinbo Wang\n",
    "* Data creator: Jaison Karin\n",
    "* CESM_HR project: Ping Chang et al.\n",
    "\n",
    "This note book is written to be run on AWS cloud environment hosted by hub.openveda.cloud or similar platforms such as those maintained by 2i2c. \n",
    "\n",
    "05/18/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809697ba-9049-4e10-91eb-597525135e42",
   "metadata": {},
   "source": [
    "## Load and examine data directly from S3\n",
    "\n",
    "The s3fs module, provided by AWS, allows Python to interact with S3 as if it were a local filesystem. It’s essential for reading files (like NetCDF) from S3 buckets. Below is a complete example demonstrating the specific operations needed to use s3fs to load a NetCDF file, with Dask for lazy loading and an option to convert to Zarr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a963399-8436-40ec-9d93-b2b768acaee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['odsl/cesm_hr_1x1/data_CESM_HR_E03_regrid_1x1deg_pop.h.PD.200101-210001.nc',\n",
       " 'odsl/cesm_hr_1x1/data_CESM_HR_E03_regrid_1x1deg_pop.h.SALT.200101-210001.nc',\n",
       " 'odsl/cesm_hr_1x1/data_CESM_HR_E03_regrid_1x1deg_pop.h.TEMP.200101-210001.nc',\n",
       " 'odsl/cesm_hr_1x1/data_CESM_HR_E03_regrid_1x1deg_pop.h.nday1.HMXL.200101-210001.nc',\n",
       " 'odsl/cesm_hr_1x1/data_CESM_HR_E03_regrid_1x1deg_pop.h.nday1.KMT.200101-210001.nc',\n",
       " 'odsl/cesm_hr_1x1/data_CESM_HR_E03_regrid_1x1deg_pop.h.nday1.SHF.200101-210001.nc',\n",
       " 'odsl/cesm_hr_1x1/data_CESM_HR_E03_regrid_1x1deg_pop.h.nday1.SHF_QSW.200101-210001.nc',\n",
       " 'odsl/cesm_hr_1x1/data_CESM_HR_E03_regrid_1x1deg_pop.h.nday1.SSH.200101-210001.nc',\n",
       " 'odsl/cesm_hr_1x1/data_CESM_HR_E03_regrid_1x1deg_pop.h.nday1.SST.200101-210001.nc',\n",
       " 'odsl/cesm_hr_1x1/data_CESM_HR_E03_regrid_1x1deg_pop.h.nday1.TAUX.200101-210001.nc',\n",
       " 'odsl/cesm_hr_1x1/data_CESM_HR_E03_regrid_1x1deg_pop.h.nday1.TAUY.200101-210001.nc']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import s3fs\n",
    "import xarray as xr\n",
    "\n",
    "# Initialize S3 filesystem\n",
    "s3 = s3fs.S3FileSystem(anon=False, key=\"AKIASWKTMBTOJEIYHZS2\", secret=\"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\") #read only access\n",
    "s3_path = \"s3://odsl/cesm_hr_1x1/*nc\"\n",
    "\n",
    "# Open dataset with Dask chunking\n",
    "file_names = s3.glob(s3_path)\n",
    "display(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025717fc-f91c-4a53-a618-cdc8677d618b",
   "metadata": {},
   "source": [
    "## Load data using xarray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ef6395-3e3f-4e60-9975-228f9fb6adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_data=xr.open_dataset(s3.open(file_names[7],mode='rb'), engine='h5netcdf', chunks={'time': 12})\n",
    "nc_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0f300c-731e-4a88-86a6-6880089c64ce",
   "metadata": {},
   "source": [
    "## Example: Perform 1-yr mean at the surface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9448c4a-5ed7-4d02-adaa-51d768566c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh=nc_data.SSH[:12,...].mean(dim='time') # Computation is not yet done at this step as the file was openned with Dask (chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59229b9-396a-49cd-97de-7ac121564db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_1ymean=ssh.compute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470d194-c4be-48ae-b7df-0648d00919cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_1ymean.plot(vmin=-2,vmax=2)\n",
    "print(ssh_1ymean[:20,100]) #Show that the missing values are filled with nan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6113436-521a-4d48-8c68-8dc19e02fef0",
   "metadata": {},
   "source": [
    "## Example: global mean Sea Surface height over the 100 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd538a84-1388-48f1-a85c-c408a65309aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_mean(nc_data):\n",
    "    \"\"\" nc_data is something like this:\n",
    "    nc_data=xr.open_dataset(s3.open(file_names[7],mode='rb'), engine='h5netcdf', chunks={'time': 12})\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    # Extract variables\n",
    "    dd = nc_data.SSH  # Shape: (t, y, x)\n",
    "    lon = nc_data.LON    # Shape: (y, x)\n",
    "    lat = nc_data.LAT    # Shape: (y, x)\n",
    "    \n",
    "    # Earth's radius in meters\n",
    "    R = 6371000\n",
    "    \n",
    "    # Convert lat and lon to radians\n",
    "    lat_rad = np.deg2rad(lat)\n",
    "    lon_rad = np.deg2rad(lon)\n",
    "    \n",
    "    # Compute differences in latitude and longitude (in radians)\n",
    "    dlat = xr.DataArray(\n",
    "            np.abs(np.diff(lat_rad, axis=0, prepend=lat_rad[0:1, :])),\n",
    "            dims=['y_regr', 'x_regr'],\n",
    "            coords=lat.coords\n",
    "        ).interp(y_regr=lat.y_regr, method='nearest')  # Interpolate to original y dimension\n",
    "\n",
    "    dlon = xr.DataArray(\n",
    "            np.abs(np.diff(lon_rad, axis=1, prepend=lon_rad[:, 0:1])),\n",
    "            dims=['y_regr', 'x_regr'],\n",
    "            coords=lon.coords\n",
    "        ).interp(x_regr=lon.x_regr, method='nearest')  # Interpolate to original x dimension\n",
    "            \n",
    "    # Compute grid cell area: A = R^2 * cos(lat) * Δlat * Δlon\n",
    "    # Use mean latitude for cos(lat) to align shapes\n",
    "    cos_lat = np.cos(lat_rad)\n",
    "    area = (R ** 2) * cos_lat * dlat * dlon\n",
    "    \n",
    "    # Ensure area and salt have compatible shapes\n",
    "    # Trim area to match salt's shape if needed (due to diff reducing dimensions)\n",
    "    \n",
    "    area = area.where(dd[0,...].notnull(), 0)  # Mask areas where salt is NaN (e.g., land), assume dd is on (time,lat,lon)\n",
    "    \n",
    "    # Compute area-weighted salinity\n",
    "    weighted = dd * area\n",
    "    \n",
    "    # Calculate global mean: sum(weighted_salt) / sum(area)\n",
    "    global_mean = weighted.sum(dim=['y_regr', 'x_regr']) / area.sum(dim=['y_regr', 'x_regr'])\n",
    "    \n",
    "    # Execute computation with Dask\n",
    "    result = global_mean.compute()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f58b7-7321-496a-8caa-2abee4fcaa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mean_ssh=global_mean(nc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f96ce-da7d-423e-9a52-aaffecb22c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
